[
  {
    "date": "2025-08-29",
    "title": "üîç Confidence Calibration: What Really Drives AI Uncertainty?",
    "slug": "confidence_calibration_ai_uncertainty",
    "excerpt": "A deep dive into how reinforcement learning trained models determine confidence scores and whether they're actually based on logical reasoning or something else entirely. Through systematic error injection experiments, I uncover surprising insights about what really drives AI uncertainty.",
    "category": "Research"
  },
  {
    "date": "2025-03-26",
    "title": "üìÑ Paper Highlight 6 ‚Äì SFT Memorizes, RL Generalizes",
    "slug": "paper_highlight_6_rl_vs_sft",
    "excerpt": "A comparative study of foundation model post-training strategies, examining how supervised fine-tuning leads to memorization while reinforcement learning promotes generalization.",
    "category": "Technology"
  },
  {
    "date": "2025-07-21",
    "title": "ü§ó SmolVLM Viz: Exploring Vision-Language-Model Attention ",
    "slug": "smolvlm_viz_exploring_attention",
    "excerpt": "Ever wondered what a Vision-Language Model is actually looking at when it describes an image? I built an interactive tool that lets you peek inside SmolVLM's attention patterns, revealing exactly which parts of an image the model focuses on for each word it generates.",
    "category": "Technology"
  },
  {
    "date": "2025-06-15",
    "title": "üìÑ Paper Deep Dive ‚Äì Sparse Autoencoders Find Highly Interpretable Features in Language Models",
    "slug": "paper_deep_dive_sparse_autoencoders",
    "excerpt": "A deep dive into sparse autoencoders and their application in mechanistic interpretability of language models.",
    "category": "Technology"
  },
  {
    "date": "2025-06-24",
    "title": "üß† Genuine Reasoning or Clever Mimicry? Evidence for Algorithmic Strategies in Language Models",
    "slug": "reasoning_traces_grpo/reasoning-traces-grpo-llms",
    "excerpt": "Do LLMs really reason, or just mimic? I train a model on the Countdown game and find it learns a true algorithm: always start with the biggest number. By peeking inside, I show this isn't just mimicry‚Äîit's real algorithmic strategy.",
    "category": "Research"
  },
  {
    "date": "2025-01-15",
    "title": "üìÑ Paper Highlight 5 ‚Äì DeepSeek-R1: Incentivizing Reasoning Capability in LLMs",
    "slug": "paper_highlight_5_deepseek",
    "excerpt": "A review of DeepSeek's groundbreaking reasoning models that outperformed OpenAI at lower cost through innovative reinforcement learning techniques and open-source transparency.",
    "category": "Technology"
  },
  {
    "date": "2024-07-29",
    "title": "ü§ñ From Scratch: The  Transformer",
    "slug": "from_scratch_1_transformer_complete",
    "excerpt": "A deep dive into the Transformer architecture, exploring its components and how they work together to enable powerful language modeling.",
    "category": "Technology"
  }
]